{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9c55446680d5435dcfad149676b5f9bdd40bd2288f3a0546b701a7eed2675e86"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing nltk\n",
    "import nltk \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\guilh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\guilh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\guilh\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''\n",
    "baby\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('baby', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tokenized = word_tokenize(sentence)\n",
    "tagged  = pos_tag(tokenized)\n",
    "tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_tagger (words):\n",
    "    tagged = pos_tag(words)\n",
    "    results = []\n",
    "    for word, tag in tagged:\n",
    "        if tag.startswith('N'): results.append((word, 'n'))\n",
    "        if tag.startswith('V'): results.append((word, 'v'))\n",
    "        if tag.startswith('R'): results.append((word, 'r'))\n",
    "        # this 'a' tag is not recognized in wornet synset and I don't know why\n",
    "        # if tag.startswith('JJ'): results.append((word, 'a'))\n",
    "    return results\n",
    "\n",
    "def wordnet_tag(tag):\n",
    "    if tag == 'n': return wordnet.NOUN\n",
    "    if tag == 'v': return wordnet.VERB\n",
    "    if tag == 'r': return wordnet.ADV\n",
    "    # this 'a' tag is not recognized in wornet synset and I don't know why\n",
    "    # if tag == 'a': return wordnet.ADJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('baby', 'n')]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "tagged_proper = synonym_tagger(tokenized)\n",
    "tagged_proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synonyms(word_tagged, dict, treshold):\n",
    "    word, tag = word_tagged\n",
    "    num_syns = 0\n",
    "    lemma = lemmatizer.lemmatize(word)\n",
    "    try:\n",
    "        word_syn = wordnet.synset(lemma + '.' + tag + '.01')\n",
    "\n",
    "        for syn in wordnet.synsets(word, wordnet_tag(tag)):\n",
    "\n",
    "            similarity = word_syn.wup_similarity(syn)\n",
    "            if similarity < treshold: break\n",
    "\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.name() not in [x[0] for x in dict[word]]: \n",
    "                    dict[word].append((lemma.name(), similarity))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_dict = {}\n",
    "for word, tag in tagged_proper: syn_dict[word] = []\n",
    "\n",
    "for word_tag in tagged_proper:\n",
    "    find_synonyms(word_tag, syn_dict, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'baby': [('baby', 1.0),\n",
       "  ('babe', 1.0),\n",
       "  ('infant', 1.0),\n",
       "  ('child', 0.631578947368421),\n",
       "  ('sister', 0.5454545454545454)]}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "syn_dict"
   ]
  },
  {
   "source": [
    "actually generating sentences based on the synonyms created\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   word     syn tag       sim\n",
       "0  baby    baby   n  1.000000\n",
       "1  baby    babe   n  1.000000\n",
       "2  baby  infant   n  1.000000\n",
       "3  baby   child   n  0.631579\n",
       "4  baby  sister   n  0.545455"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>syn</th>\n      <th>tag</th>\n      <th>sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>baby</td>\n      <td>baby</td>\n      <td>n</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>baby</td>\n      <td>babe</td>\n      <td>n</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>baby</td>\n      <td>infant</td>\n      <td>n</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>baby</td>\n      <td>child</td>\n      <td>n</td>\n      <td>0.631579</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>baby</td>\n      <td>sister</td>\n      <td>n</td>\n      <td>0.545455</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['word', 'syn', 'tag', 'sim'])\n",
    "\n",
    "for word in syn_dict.keys():\n",
    "    for syn in syn_dict[word]:\n",
    "        row = {\n",
    "            'word': word, \n",
    "            'syn': syn[0],\n",
    "            'tag': dict(tagged_proper)[word],\n",
    "            'sim': syn[1]\n",
    "        }\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   word     syn       sim  tag_n  tag_v  tag_r  tag_a\n",
       "0  baby    baby  1.000000      1      0      0      0\n",
       "1  baby    babe  1.000000      1      0      0      0\n",
       "2  baby  infant  1.000000      1      0      0      0\n",
       "3  baby   child  0.631579      1      0      0      0\n",
       "4  baby  sister  0.545455      1      0      0      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>syn</th>\n      <th>sim</th>\n      <th>tag_n</th>\n      <th>tag_v</th>\n      <th>tag_r</th>\n      <th>tag_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>baby</td>\n      <td>baby</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>baby</td>\n      <td>babe</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>baby</td>\n      <td>infant</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>baby</td>\n      <td>child</td>\n      <td>0.631579</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>baby</td>\n      <td>sister</td>\n      <td>0.545455</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# df = pd.concat([df, pd.get_dummies(df['tag'], columns=['n','v','r','a'])], axis='columns').reset_index(drop=True).drop(columns=['tag'])\n",
    "df2 = pd.get_dummies(df, columns=['tag'], prefix=None)\n",
    "tags = ['tag_n', 'tag_v', 'tag_r', 'tag_a']\n",
    "for tag in tags:\n",
    "    if tag not in df2: df2[tag] = 0\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   word     syn       sim  tag_n  tag_v  tag_r  tag_a\n",
       "0  baby    baby  1.000000      1      0      0      0\n",
       "1  baby    babe  1.000000      1      0      0      0\n",
       "2  baby  infant  1.000000      1      0      0      0\n",
       "3  baby   child  0.631579      1      0      0      0\n",
       "4  baby  sister  0.545455      1      0      0      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>syn</th>\n      <th>sim</th>\n      <th>tag_n</th>\n      <th>tag_v</th>\n      <th>tag_r</th>\n      <th>tag_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>baby</td>\n      <td>baby</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>baby</td>\n      <td>babe</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>baby</td>\n      <td>infant</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>baby</td>\n      <td>child</td>\n      <td>0.631579</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>baby</td>\n      <td>sister</td>\n      <td>0.545455</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['tag'])\n",
    "\n",
    "# Check if there are missing columns and create them\n",
    "tags = ['tag_n', 'tag_v', 'tag_r', 'tag_a']\n",
    "for tag in tags: \n",
    "    if tag not in df: df[tag] = 0\n",
    "\n",
    "substitution_order_preference = ['tag_r', 'tag_n', 'tag_v']\n",
    "df.sort_values(substitution_order_preference + ['sim'], ascending=False,  ignore_index=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to delete repeating rows\n",
    "df = df[df['word'] != df['syn']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index  word     syn       sim  tag_n  tag_v  tag_r  tag_a\n",
       "0      1  baby    babe  1.000000      1      0      0      0\n",
       "1      2  baby  infant  1.000000      1      0      0      0\n",
       "2      3  baby   child  0.631579      1      0      0      0\n",
       "3      4  baby  sister  0.545455      1      0      0      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>word</th>\n      <th>syn</th>\n      <th>sim</th>\n      <th>tag_n</th>\n      <th>tag_v</th>\n      <th>tag_r</th>\n      <th>tag_a</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>baby</td>\n      <td>babe</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>baby</td>\n      <td>infant</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>baby</td>\n      <td>child</td>\n      <td>0.631579</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>baby</td>\n      <td>sister</td>\n      <td>0.545455</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generator(sentence, synonym_dict, num_sentences):\n",
    "    sentences = []\n",
    "    sentence_counter = 0\n",
    "\n",
    "    tokenized = word_tokenize(sentence)\n",
    "\n",
    "    for index in range(df.shape[0]):\n",
    "        word = df.at[index, 'word']\n",
    "        syn = df.at[index, 'syn']\n",
    "        word_index = tokenized.index(word)\n",
    "        sent = [t for t in tokenized]\n",
    "        sent[word_index] = syn.replace('_', ' ')\n",
    "        untokenized_sentence = TreebankWordDetokenizer().detokenize(sent)\n",
    "        sentences.append(untokenized_sentence)\n",
    "        sentence_counter += 1\n",
    "\n",
    "        if sentence_counter >= num_sentences: break\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['babe', 'infant', 'child', 'sister']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sentence_generator(sentence, syn_dict, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Testing on real methods\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similar_sentence_generator import generate_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         description  Measuring  Plating  \\\n",
       "0  Put the mushrooms, chard, oil, garlic, chilli,...          0        0   \n",
       "1  Bring a large pan of salted water to the boil,...          0        0   \n",
       "2  Add the drained pasta and chopped tomatoes to ...          0        0   \n",
       "3  Toast the cumin seeds, fennel seeds and black ...          0        0   \n",
       "4  Transfer to a mortar and pestle and grind to a...          0        0   \n",
       "\n",
       "   Smoking  Toasting  Microwaving  Air Frying  Double Boiler  Bain Marie  \\\n",
       "0        0         0            0           0              0           0   \n",
       "1        0         0            0           0              0           0   \n",
       "2        0         0            0           0              0           0   \n",
       "3        0         1            0           0              0           0   \n",
       "4        0         0            0           0              0           0   \n",
       "\n",
       "   Reducing  ...  Seasoning  Salting  Slicing  Chopping Fruits  \\\n",
       "0         0  ...          0        0        0                0   \n",
       "1         0  ...          0        0        0                0   \n",
       "2         0  ...          0        0        0                0   \n",
       "3         0  ...          0        0        0                0   \n",
       "4         0  ...          0        0        0                0   \n",
       "\n",
       "   Chopping Mushroom  Chopping Herbs  Mincing  Batonnet  Dicing  \\\n",
       "0                  0               0        0         0       0   \n",
       "1                  0               0        0         0       0   \n",
       "2                  0               0        0         0       0   \n",
       "3                  0               0        0         0       0   \n",
       "4                  0               0        0         0       0   \n",
       "\n",
       "   Roughly Chopping  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n      <th>Measuring</th>\n      <th>Plating</th>\n      <th>Smoking</th>\n      <th>Toasting</th>\n      <th>Microwaving</th>\n      <th>Air Frying</th>\n      <th>Double Boiler</th>\n      <th>Bain Marie</th>\n      <th>Reducing</th>\n      <th>...</th>\n      <th>Seasoning</th>\n      <th>Salting</th>\n      <th>Slicing</th>\n      <th>Chopping Fruits</th>\n      <th>Chopping Mushroom</th>\n      <th>Chopping Herbs</th>\n      <th>Mincing</th>\n      <th>Batonnet</th>\n      <th>Dicing</th>\n      <th>Roughly Chopping</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Put the mushrooms, chard, oil, garlic, chilli,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bring a large pan of salted water to the boil,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Add the drained pasta and chopped tomatoes to ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Toast the cumin seeds, fennel seeds and black ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Transfer to a mortar and pestle and grind to a...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 53 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df = pd.read_pickle('hand_classified_methods/classified_methods')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Add more lemon juice, garlic, cumin or salt to taste. Turn out into a dinner plate, and make smooth with the back of a spoon. Drizzle with extra virgin olive oil and scatter with the reserved chickpeas. \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Add to a greater extent lemon juice, garlic, cumin or salt to taste . Turn out into a dinner plate, and make smooth with the back of a spoon . Drizzle with extra virgin olive oil and scatter with the reserved chickpeas.',\n",
       " 'attention deficit disorder more lemon juice, garlic, cumin or salt to taste . Turn out into a dinner plate, and make smooth with the back of a spoon . Drizzle with extra virgin olive oil and scatter with the reserved chickpeas.',\n",
       " 'ADD more lemon juice, garlic, cumin or salt to taste . Turn out into a dinner plate, and make smooth with the back of a spoon . Drizzle with extra virgin olive oil and scatter with the reserved chickpeas.',\n",
       " 'attention deficit hyperactivity disorder more lemon juice, garlic, cumin or salt to taste . Turn out into a dinner plate, and make smooth with the back of a spoon . Drizzle with extra virgin olive oil and scatter with the reserved chickpeas.',\n",
       " 'ADHD more lemon juice, garlic, cumin or salt to taste . Turn out into a dinner plate, and make smooth with the back of a spoon . Drizzle with extra virgin olive oil and scatter with the reserved chickpeas.']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "row=6\n",
    "method = df.at[row,'description']\n",
    "print(method)\n",
    "generate_sentences(method, 5,similarity_treshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Add the drained pasta and chopped tomatoes to the roasting tin and mix good . Scatter over the remaining sage, feta and breadcrumbs and bake for a further 30 minutes, or until golden and bubbling . Serve hot.',\n",
       " 'Add the drained pasta and chopped tomatoes to the roasting tin and mix easily . Scatter over the remaining sage, feta and breadcrumbs and bake for a further 30 minutes, or until golden and bubbling . Serve hot.',\n",
       " 'Add the drained pasta and chopped tomatoes to the roasting tin and mix considerably . Scatter over the remaining sage, feta and breadcrumbs and bake for a further 30 minutes, or until golden and bubbling . Serve hot.',\n",
       " 'Add the drained pasta and chopped tomatoes to the roasting tin and mix substantially . Scatter over the remaining sage, feta and breadcrumbs and bake for a further 30 minutes, or until golden and bubbling . Serve hot.',\n",
       " 'Add the drained pasta and chopped tomatoes to the roasting tin and mix intimately . Scatter over the remaining sage, feta and breadcrumbs and bake for a further 30 minutes, or until golden and bubbling . Serve hot.']"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": []
  }
 ]
}